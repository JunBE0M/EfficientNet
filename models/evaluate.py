import os
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from timm.models import create_model
from PIL import Image
from sklearn.metrics import roc_auc_score, accuracy_score

# ê²½ë¡œ ì„¤ì •
IMG_FOLDER_PATH = '../data/images' 
CHECKPOINT_DIR = '../checkpoints' # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ í´ë”
TEST_CSV = '../data/test_labels.csv' 

NUM_CLASSES = 5 
IMAGE_SIZE = 224
MODEL_NAME = 'efficientnet_b4' 
BATCH_SIZE = 32              
LABELS = ['Edema', 'Effusion', 'Mass', 'Nodule', 'Pneumothorax']

MEAN = [0.485, 0.456, 0.406]
STD = [0.229, 0.224, 0.225]


class ChestXrayDataset(Dataset):
    def __init__(self, csv_file, img_dir, transform=None):
        self.labels_frame = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform
        self.img_col = self.labels_frame.columns[0]
        self.labels_np = self.labels_frame.iloc[:, 1:].values.astype('float32')
    
    def __len__(self): return len(self.labels_frame)
    
    def __getitem__(self, idx):
        img_name = self.labels_frame.iloc[idx][self.img_col]
        img_path = os.path.join(self.img_dir, img_name)
        # ì´ë¯¸ì§€ íŒŒì¼ëª…ì„ í™•ì¸í•˜ê³ , íŒŒì¼ì´ ì—†ì„ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬
        if not os.path.exists(img_path):
            # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ê±°ë‚˜ ê±´ë„ˆë›¸ ìˆ˜ ìˆìœ¼ë‚˜, ì—¬ê¸°ì„œëŠ” ì—ëŸ¬ë¥¼ ë°œìƒì‹œì¼œ ë””ë²„ê¹…ì„ ë•ìŠµë‹ˆë‹¤.
            raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")

        image = Image.open(img_path).convert('RGB')
        label = self.labels_np[idx] 
        if self.transform: image = self.transform(image)
        return image, torch.tensor(label)


def get_transforms():
    transform_train = transforms.Compose([
        transforms.Resize(256), 
        transforms.RandomCrop(IMAGE_SIZE), 
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=MEAN, std=STD),
    ])
    
    # â­ í…ŒìŠ¤íŠ¸/ê²€ì¦ì— ì‚¬ìš©ë˜ëŠ” ì „ì²˜ë¦¬ (RandomCrop ë¯¸ì‚¬ìš©)
    transform_val_test = transforms.Compose([
        transforms.Resize(IMAGE_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=MEAN, std=STD),
    ])
    return transform_train, transform_val_test

def get_data_loaders(img_dir, test_csv, batch_size):

    _, transform_val_test = get_transforms()
    
    test_dataset = ChestXrayDataset(csv_file=test_csv, img_dir=img_dir, transform=transform_val_test)

    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=os.cpu_count() // 2 if os.cpu_count() else 0)
    
    return test_loader

def get_efficientnet_model(model_name=MODEL_NAME, num_classes=NUM_CLASSES, pretrained=False):

    # pretrained=Falseë¡œ ì„¤ì •í•˜ì—¬ ê°€ì¤‘ì¹˜ íŒŒì¼ë¡œ ëª¨ë¸ì„ ì´ˆê¸°í™”
    model = create_model(model_name, pretrained=pretrained, num_classes=num_classes)
    return model

# ëª¨ë¸ í‰ê°€ í•¨ìˆ˜
def evaluate_model():
    print("\ní…ŒìŠ¤íŠ¸ í‰ê°€ ì‹œì‘")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"í‰ê°€ ì¥ì¹˜: {device}")
    
    # Test Dataloader
    test_loader = get_data_loaders(IMG_FOLDER_PATH, TEST_CSV, BATCH_SIZE)
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ. (ì´ {len(test_loader.dataset)}ê°œ)")
    
    checkpoint_path = os.path.join(CHECKPOINT_DIR, f"best_{MODEL_NAME}_5class.pth")
    
    # Model load
    model = get_efficientnet_model(pretrained=False)
    
    if not os.path.exists(checkpoint_path):
        print(f"\nì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. {checkpoint_path}")
        return

    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ë° ê°€ì¤‘ì¹˜ ì ìš©

    checkpoint = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint['model'])
    model = model.to(device)
    model.eval()
    print(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

    all_probabilities = []
    all_true_labels = []

    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            logits = model(images) 
            probabilities = torch.sigmoid(logits) 

            all_probabilities.append(probabilities.cpu().numpy())
            all_true_labels.append(labels.cpu().numpy())

    probabilities_np = np.concatenate(all_probabilities, axis=0)
    true_labels_np = np.concatenate(all_true_labels, axis=0)

    # ROC ê³„ì‚°
    avg_auc = roc_auc_score(true_labels_np, probabilities_np, average='macro')
    print(f"\n=======================================================")
    print(f"ğŸŒŸ ìµœì¢… í…ŒìŠ¤íŠ¸ AUC-ROC (Macro Avg): {avg_auc:.4f}")
    print(f"=======================================================")
        
    # í´ë˜ìŠ¤ë³„ AUC-ROC
    print("\n[í´ë˜ìŠ¤ë³„ AUC-ROC]")
    for i, label in enumerate(LABELS):
        auc_i = roc_auc_score(true_labels_np[:, i], probabilities_np[:, i])
        print(f"   - {label}: {auc_i:.4f}")

    # ì •í™•ë„
    threshold = 0.5
    predictions_np = (probabilities_np > threshold).astype(int)
    subset_accuracy = accuracy_score(true_labels_np, predictions_np)
    hamming_accuracy = np.mean(predictions_np == true_labels_np)

    print(f"\n[ì •í™•ë„ ì§€í‘œ (ì„ê³„ê°’ {threshold})]")
    print(f"   - Subset Accuracy (ì™„ë²½ ì¼ì¹˜): {subset_accuracy:.4f}")
    print(f"   - Label Accuracy (ê°œë³„ ë¼ë²¨ ì¼ì¹˜): {hamming_accuracy:.4f}")


if __name__ == '__main__':
    evaluate_model()